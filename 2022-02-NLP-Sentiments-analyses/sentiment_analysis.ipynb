{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_Gm-cSqpXa1"
   },
   "source": [
    "# Analyse de sentiments\n",
    "\n",
    "C'est désormais un problème classique de machine learning. D'un côté, du texte, de l'autre une appréciation, le plus souvent binaire, positive ou négative mais qui pourrait être graduelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from os import getcwd\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\WORK\\\\wokspace-simplon3\\\\simplon\\\\2022-02-NLP-Sentiments-analyses\\\\'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------\n",
    "#                               MAIN\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "verbose = False\n",
    "verboseMain = False\n",
    "\n",
    "# Récupère le répertoire du programme\n",
    "file_path = getcwd() + \"\\\\\"\n",
    "file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_paTGYppXa7"
   },
   "source": [
    "## Les données\n",
    "\n",
    "On récupère les données depuis le site UCI [Sentiment Labelled Sentences Data Set](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences). \n",
    "\n",
    "Il y a trois fichiers textes à importer et à concaténer pour former un dataset avec deux colonnes:\n",
    "- Une \"texte\" comportant le contenu du commentaire\n",
    "- Une \"sentiment\" comportant une note de 0 ou 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n",
      "Chargement des données (1000, 2) (748, 2) (1000, 2) .......................................... END\n"
     ]
    }
   ],
   "source": [
    "print(\"Chargement des données...\")\n",
    "file_name_amazon_label = \"amazon_cells_labelled.txt\"\n",
    "file_name_imdb_labelled = \"imdb_labelled.txt\"\n",
    "file_name_yelp_labelled = 'yelp_labelled.txt'\n",
    "\n",
    "df_origin_amazon_label = pd.read_csv(file_path+\"\\\\data\\\\\"+file_name_amazon_label, sep='\\t', header=None)\n",
    "df_origin_imdb_labelled = pd.read_csv(file_path+\"\\\\data\\\\\"+file_name_imdb_labelled, sep='\\t', header=None)\n",
    "df_origin_yelp_labelled= pd.read_csv(file_path+\"\\\\data\\\\\"+file_name_yelp_labelled, sep='\\t', header=None)\n",
    "\n",
    "print(\"Chargement des données\", df_origin_amazon_label.shape, df_origin_imdb_labelled.shape,  df_origin_yelp_labelled.shape, \".......................................... END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_amazon_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin_amazon_label[\"website\"] = \"amazon\"\n",
    "df_origin_imdb_labelled[\"website\"] = \"imdb\"\n",
    "df_origin_yelp_labelled[\"website\"] = \"yelp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2748, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1 website\n",
       "0  So there is no way for me to plug it in here i...  0  amazon\n",
       "1                        Good case, Excellent value.  1  amazon\n",
       "2                             Great for the jawbone.  1  amazon\n",
       "3  Tied to charger for conversations lasting more...  0  amazon\n",
       "4                                  The mic is great.  1  amazon"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_full = df_origin_amazon_label.append(df_origin_imdb_labelled)\n",
    "df_origin_full = df_origin_full.append(df_origin_yelp_labelled)\n",
    "print(df_origin_full.shape)\n",
    "df_origin_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'connotation', 'website'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_full = df_origin_full.rename(columns={0: \"sentence\", 1: \"connotation\"})\n",
    "df_origin_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXDvLY2ZDVkO"
   },
   "source": [
    "#### Questions préalables: \n",
    "- Quelle est la taille du dataset ?\n",
    "- Comment est distribuée la variable sentiment ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin_full[\"connotation\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Bri_R2PDfGv"
   },
   "source": [
    "#### Question 1: Combien y a t'il de mots dans l'ensemble du corpus ? Sont-ils \"homogènes\" ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EscnTgSGdnsV"
   },
   "source": [
    "### Import du module permettant le traitement de texte: nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmkgemE8gLIz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VzY9vw9DyNq"
   },
   "source": [
    "#### Consigne 1: Récupérer le corpus de mots sans la ponctuation ni les stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNtZjfkm3KuJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_--nXldFphn"
   },
   "source": [
    "#### Question 2: Combien de mots restent-ils ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcQXTEey3LaZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZSwQ69FpXa-"
   },
   "source": [
    "## Exercice 1 : approche td-idf\n",
    "\n",
    "La cible est la colonne *sentiment*, les deux autres colonnes sont les features. Il faudra utiliser les prétraitements [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), [TF-IDF](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html). L'un d'entre eux n'est pas nécessaire depuis la version [0.20.0](http://scikit-learn.org/stable/whats_new.html#sklearn-preprocessing) de *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2_dDBUxEoc2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4s9adDJEpsx"
   },
   "source": [
    "#### Consigne 2: Utiliser OneHotEncoder ou CountVectorizer pour représenter les données sous forme d'une matrice contenant autant de colonnes que de mots dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qunw7as0pXa_"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUcM-S7SFb-5"
   },
   "source": [
    "#### Consigne 3: lancer un modèle de classification pour prédire les sentiments de 30% des observations\n",
    "\n",
    "\n",
    "\n",
    "*   Séparer échantillon train / test\n",
    "*   Entrainer un modèle de classification\n",
    "*   Afficher la matrice de confusion\n",
    "*   Calculer l'accuracy, la précision et le recall\n",
    "*   Votre modèle est-il soumis à un overfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWXIE3jGK5sS"
   },
   "source": [
    "#### Consigne 4: Utiliser TF-IDF pour représenter les données et relancer un modèle de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O-l47TebpXbA"
   },
   "source": [
    "## Exercice 2 : word2vec\n",
    "\n",
    "On utilise l'approche [word2vec](https://en.wikipedia.org/wiki/Word2vec) du module [gensim](https://radimrehurek.com/gensim/models/word2vec.html) ou [spacy](https://spacy.io/usage/vectors-similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Z0QugRgkXDE"
   },
   "source": [
    "#### Consigne 5: Utiliser Word2vec pour représenter les données et relancer un modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lke42PWFpXbB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8RiKV-gSpXbC"
   },
   "source": [
    "## Exercice 3 : Comparer les deux approches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia88RvTrkemu"
   },
   "source": [
    "#### Consigne 6: Faire un graphique montrant les courbes ROC associées au deux modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjiCxvFJg4TQ"
   },
   "source": [
    "#### Consigne 7: Faire un graphique montrant les courbes Precision-Recall associées aux deux modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfAqKn0ehUHl"
   },
   "source": [
    "### BONUS: reprendre l'étape de One_hot_encoding et ajouter une étape de réduction de dimension (type ACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gu5Lbz2rg22u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQS0UJb1DaAi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Q_8h1ArpXbD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TD2A_sentiment_analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

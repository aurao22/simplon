{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enoncé\n",
    "\n",
    "Vous avez participé à une compétition sur Kaggle sur le jeu de données de Titanic (celle-ci existe, les curieux peuvent la retrouver sur Kaggle !). Vous avez pour cela à votre disposition [une liste de 891 passagers](https://www.kaggle.com/c/titanic), contenant les caractéristiques suivantes :\n",
    "\n",
    "\n",
    "- PassengerID : Identifiant du passager\n",
    "- Survived : Indicateur de survi d'un passager (1 si le passager a survecu, 0 s’il est décédé)\n",
    "- Pclass: Classe du passager (1 = 1ère classe, 2 = 2ème classe, 3 = 3ème classe)\n",
    "- Name : Nom et titre du passager\n",
    "- Sex : Sexe du passager\n",
    "- Age : Age du passager (Décimal si inférieur à 1, estimé si de la forme xx.5)\n",
    "- SibSp : Nombre d’époux, de frères et de soeurs présents à bord\n",
    "- Parch : Nombre de parents ou d’enfants présents à bord \n",
    "- Ticket : Numéro du ticket \n",
    "- Fare : Tarif des tickets (Le prix est indiqué en £ et pour un seul achat (peut correspondre à plusieurs tickets)\n",
    "- Cabin : Numéro de Cabine\n",
    "- Embarked : Port d’embarcation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\t \t\n",
    "\n",
    "# Exercice\n",
    "\n",
    "La compétition a été l’occasion de revenir sur ce jeu de données très célèbre, et plusieurs tâches étaient attendues, :\n",
    "- identifier les facteurs favorisants la survie d'un passager par rapport à un autre, en dressant une typologie des survivants\n",
    "- créer un algorithme qui pourrait prédire la survie d'un individu à partir de ces caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import statsmodels.formula.api as smf\n",
    "import itertools\n",
    "from random import randint\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "try:\n",
    "    from sklearn.utils._testing import ignore_warnings\n",
    "except ImportError:\n",
    "    from sklearn.utils.testing import ignore_warnings\n",
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from datetime import datetime\n",
    "from os import getcwd\n",
    "from function import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f54d2b",
   "metadata": {},
   "source": [
    "## 1. Charger vos données dans un DataFrame Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------------------------\n",
    "#                               MAIN\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "verbose = False\n",
    "verboseMain = False\n",
    "\n",
    "print(\"Chargement des données...\")\n",
    "# Récupère le répertoire du programme\n",
    "file_path = getcwd() + \"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données train: (891, 18) , test: (418, 17) .................................. END\n"
     ]
    }
   ],
   "source": [
    "file_name_test = 'titanic_dataset_kaggle_test_process_2022-01-15-18_44_17.csv'\n",
    "file_name_train = 'titanic_dataset_kaggle_train_process_2022-01-15-18_44_17.csv'\n",
    "file_name_test_y = 'titanic_dataset_kaggle_test_y.csv'\n",
    "\n",
    "file_separator = ','\n",
    "\n",
    "df_origin_train = pd.read_csv(file_path+file_name_train, sep=file_separator, index_col=\"PassengerId\")\n",
    "df_origin_test = pd.read_csv(file_path+file_name_test, sep=file_separator, index_col=\"PassengerId\")\n",
    "df_origin_test_y = pd.read_csv(file_path+file_name_test_y, sep=file_separator, index_col=\"PassengerId\")\n",
    "\n",
    "print(\"Chargement des données train:\", df_origin_train.shape, \", test:\", df_origin_test.shape, \".................................. END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>group</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>deck</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Last_name</th>\n",
       "      <th>First_name</th>\n",
       "      <th>Sex_cod</th>\n",
       "      <th>Titre_cod</th>\n",
       "      <th>Embarked_cod</th>\n",
       "      <th>deck_cod</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Braund</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>G</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Allen</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name   Age     Sex  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris  22.0    male   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  female   \n",
       "3                                       Heikkinen, Miss. Laina  26.0  female   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  female   \n",
       "5                                     Allen, Mr. William Henry  35.0    male   \n",
       "\n",
       "             SibSp  Parch  group     Fare Embarked deck Titre  Last_name  \\\n",
       "PassengerId                                                                \n",
       "1                1      0      1   7.2500        S    G    Mr     Braund   \n",
       "2                1      0      1  71.2833        C    C   Mrs    Cumings   \n",
       "3                0      0      0   7.9250        S    G  Miss  Heikkinen   \n",
       "4                1      0      1  53.1000        S    C   Mrs   Futrelle   \n",
       "5                0      0      0   8.0500        S    B    Mr      Allen   \n",
       "\n",
       "                                        First_name  Sex_cod  Titre_cod  \\\n",
       "PassengerId                                                              \n",
       "1                                      Owen Harris        1          7   \n",
       "2            John Bradley (Florence Briggs Thayer)        0          8   \n",
       "3                                            Laina        0          6   \n",
       "4                    Jacques Heath (Lily May Peel)        0          8   \n",
       "5                                    William Henry        1          7   \n",
       "\n",
       "             Embarked_cod  deck_cod  \n",
       "PassengerId                          \n",
       "1                       2         6  \n",
       "2                       0         2  \n",
       "3                       2         6  \n",
       "4                       2         2  \n",
       "5                       2         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>group</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>deck</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Last_name</th>\n",
       "      <th>First_name</th>\n",
       "      <th>Sex_cod</th>\n",
       "      <th>Titre_cod</th>\n",
       "      <th>Embarked_cod</th>\n",
       "      <th>deck_cod</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>34.5</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "      <td>F</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>James</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>47.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Wilkes</td>\n",
       "      <td>James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>62.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "      <td>B</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Myles</td>\n",
       "      <td>Thomas Francis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>27.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Wirz</td>\n",
       "      <td>Albert</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Hirvonen</td>\n",
       "      <td>Alexander (Helga E Lindqvist)</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name   Age  \\\n",
       "PassengerId                                                               \n",
       "892               3                              Kelly, Mr. James  34.5   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  47.0   \n",
       "894               2                     Myles, Mr. Thomas Francis  62.0   \n",
       "895               3                              Wirz, Mr. Albert  27.0   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0   \n",
       "\n",
       "                Sex  SibSp  Parch  group     Fare Embarked deck Titre  \\\n",
       "PassengerId                                                             \n",
       "892            male      0      0      0   7.8292        Q    F    Mr   \n",
       "893          female      1      0      1   7.0000        S    F   Mrs   \n",
       "894            male      0      0      0   9.6875        Q    B    Mr   \n",
       "895            male      0      0      0   8.6625        S    A    Mr   \n",
       "896          female      1      1      2  12.2875        S    E   Mrs   \n",
       "\n",
       "            Last_name                     First_name  Sex_cod  Titre_cod  \\\n",
       "PassengerId                                                                \n",
       "892             Kelly                          James        1          5   \n",
       "893            Wilkes            James (Ellen Needs)        0          6   \n",
       "894             Myles                 Thomas Francis        1          5   \n",
       "895              Wirz                         Albert        1          5   \n",
       "896          Hirvonen  Alexander (Helga E Lindqvist)        0          6   \n",
       "\n",
       "             Embarked_cod  deck_cod  \n",
       "PassengerId                          \n",
       "892                     1         5  \n",
       "893                     2         5  \n",
       "894                     1         1  \n",
       "895                     2         0  \n",
       "896                     2         4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "892                 0\n",
       "893                 1\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_test_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Typage et Organisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived          int64\n",
       "Pclass            int64\n",
       "Name             object\n",
       "Age             float64\n",
       "Sex              object\n",
       "SibSp             int64\n",
       "Parch             int64\n",
       "group             int64\n",
       "Fare            float64\n",
       "Embarked         object\n",
       "deck             object\n",
       "Titre            object\n",
       "Last_name        object\n",
       "First_name       object\n",
       "Sex_cod           int64\n",
       "Titre_cod         int64\n",
       "Embarked_cod      int64\n",
       "deck_cod          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass            int64\n",
       "Name             object\n",
       "Age             float64\n",
       "Sex              object\n",
       "SibSp             int64\n",
       "Parch             int64\n",
       "group             int64\n",
       "Fare            float64\n",
       "Embarked         object\n",
       "deck             object\n",
       "Titre            object\n",
       "Last_name        object\n",
       "First_name       object\n",
       "Sex_cod           int64\n",
       "Titre_cod         int64\n",
       "Embarked_cod      int64\n",
       "deck_cod          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_test_y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived        0\n",
       "Pclass          0\n",
       "Name            0\n",
       "Age             0\n",
       "Sex             0\n",
       "SibSp           0\n",
       "Parch           0\n",
       "group           0\n",
       "Fare            0\n",
       "Embarked        2\n",
       "deck            0\n",
       "Titre           0\n",
       "Last_name       0\n",
       "First_name      0\n",
       "Sex_cod         0\n",
       "Titre_cod       0\n",
       "Embarked_cod    0\n",
       "deck_cod        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass          0\n",
       "Name            0\n",
       "Age             0\n",
       "Sex             0\n",
       "SibSp           0\n",
       "Parch           0\n",
       "group           0\n",
       "Fare            0\n",
       "Embarked        0\n",
       "deck            0\n",
       "Titre           0\n",
       "Last_name       0\n",
       "First_name      0\n",
       "Sex_cod         0\n",
       "Titre_cod       0\n",
       "Embarked_cod    0\n",
       "deck_cod        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_test['Fare'] = df_origin_test['Fare'].fillna(0)\n",
    "df_origin_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_test_y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "La compétition a été l’occasion de revenir sur ce jeu de données très célèbre, et plusieurs tâches étaient attendues, :\n",
    "- identifier les facteurs favorisants la survie d'un passager par rapport à un autre, en dressant une typologie des survivants\n",
    "- créer un algorithme qui pourrait prédire la survie d'un individu à partir de ces caractéristiques.\n",
    "\n",
    "Vous avez été ajouté à une équipe et le travail et lancé depuis quelques semaines : à cette étape,  la mission est en réalité finie (c.f. le présent notebook). Vos co-équipiers ont travaillé dur : il faut dans un premier temps vous approprier leur travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Name', 'Age', 'Sex', 'SibSp', 'Parch', 'group',\n",
       "       'Fare', 'Embarked', 'deck', 'Titre', 'Last_name', 'First_name',\n",
       "       'Sex_cod', 'Titre_cod', 'Embarked_cod', 'deck_cod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict_columns = 'Survived'\n",
    "columns = ['Pclass', 'Sex_cod', 'Titre_cod', 'Age', 'group', 'Fare', 'Embarked_cod', 'deck_cod'] \n",
    "\n",
    "X_train = df_origin_train[columns]\n",
    "y_train = df_origin_train[to_predict_columns]\n",
    "\n",
    "X_test = df_origin_test[columns]\n",
    "y_test = df_origin_test_y[to_predict_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Manuellement j'avais les résultats suivants :</mark>\n",
    "```python\n",
    "1.0 for test ( 0.79 for train) => Logistic Regression, with: ['Pclass', 'Sex_cod', 'Titre_cod']\n",
    "1.0 for test ( 0.79 for train) => K Nearest Neighbor, with: ['Pclass', 'Sex_cod']\n",
    "1.0 for test ( 0.79 for train) => Decision Tree, with: ['Sex_cod']\n",
    "1.0 for test ( 0.79 for train) => Random Forest, with: ['Pclass', 'Sex_cod']\n",
    "1.0 for test ( 0.79 for train) => Support Vector Machine (Linear)\n",
    "0.65 for test ( 0.69 for train) => Support Vector Machine (RBF)\n",
    "0.81 for test ( 0.79 for train) => Gaussian Naive Bayes\n",
    "```\n",
    "Les paramétrages correspondants :\n",
    "```python\n",
    "LogisticReg : \n",
    "* fit_intercept= True or False\n",
    "* penalty=none or l2 or l1\n",
    "* solver=liblinear or newton-cg or lbfgs or sag or saga\n",
    "* columns = ['Pclass', 'Sex_cod', 'Titre_cod']\n",
    "\n",
    "KNN : \n",
    "* KNN = 2 :['Pclass', 'Sex_cod']\n",
    "* KNN = 4 :['Embarked_cod', 'Pclass', 'Sex_cod']\n",
    "* KNN = 1 :['Sex_cod']\n",
    "* KNN = 1 :['Sex_cod', 'Titre_cod']\n",
    "* KNN = 1 :['Embarked_cod', 'Sex_cod']\n",
    "* KNN = 7 :['Sex_cod', 'deck_cod']\n",
    "\n",
    "Decision Tree\n",
    "* criterion = gini or entropy\n",
    "* splitter=best or random\n",
    "* columns = ['Sex_cod'] (0.98 de test <=> 0.81 de train, avec ['Pclass', 'Sex_cod', 'group'])\n",
    "\n",
    "RandomForest :\n",
    "* n_estimators= de 3 à 99 \n",
    "* criterion=gini or entropy\n",
    "* columns = ['Pclass', 'Sex_cod']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58111394,  0.82737724,  0.73769513],\n",
       "       [-1.93846038, -1.56610693, -1.35557354],\n",
       "       [ 0.58111394,  0.82737724, -1.35557354],\n",
       "       ...,\n",
       "       [ 0.58111394,  0.82737724, -1.35557354],\n",
       "       [-1.93846038, -1.56610693,  0.73769513],\n",
       "       [-0.67867322,  0.82737724,  0.73769513]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer\n",
    "scaler = StandardScaler()\n",
    "X_train_transform = scaler.fit_transform(X_train[['Embarked_cod', 'Pclass', 'Sex_cod']])\n",
    "X_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ex_params = {\n",
    "            'polynomialfeatures__degree' : [2,3,4],\n",
    "            'standardscaler__penality' : [None, 'l2', 'l1', 'elasticnet'],\n",
    "            'KNeighborsClassifier__n_neighbors': [range(1,10)],\n",
    "            'KNeighborsClassifier__p': [range(1,10)],# TODO compléter les valeurs\n",
    "            'KNeighborsClassifier__metric' : ['minkowski'], # TODO compléter les valeurs\n",
    "            'KNeighborsClassifier__weights' : ['uniform', 'distance'],\n",
    "            'KNeighborsClassifier__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'DecisionTreeClassifier__criterion' : [\"gini\", \"entropy\"],\n",
    "            'DecisionTreeClassifier__splitter' : [\"best\", \"random\"],\n",
    "            'RandomForestClassifier__criterion' : [\"gini\", \"entropy\"],\n",
    "            'RandomForestClassifier__n_estimators' : [range(1,100,10)],\n",
    "            'LogisticRegression__solver' : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "            'LogisticRegression__penality' : [None, 'l2', 'l1', 'elasticnet'],\n",
    "            'LogisticRegression__fit_intercept' :[True, False],\n",
    "            'SVC__kernel': ['linear', 'rbf'] # TODO compléter les valeurs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ex_params = {\n",
    "            'polynomialfeatures__degree' : [2,3,4],\n",
    "            'standardscaler__with_mean' : [True, False],\n",
    "            'standardscaler__with_std' : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex_pipeline = make_pipeline(PolynomialFeatures(), \n",
    "                           StandardScaler(), \n",
    "                           SGDClassifier(random_state=random_state))\n",
    "grid_ex_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ex = GridSearchCV(grid_ex_pipeline,param_grid=grid_ex_params, cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('sgdclassifier',\n",
       "                                        SGDClassifier(random_state=0))]),\n",
       "             param_grid={'polynomialfeatures__degree': [2, 3, 4],\n",
       "                         'standardscaler__with_mean': [True, False],\n",
       "                         'standardscaler__with_std': [True, False]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polynomialfeatures__degree': 3,\n",
       " 'standardscaler__with_mean': False,\n",
       " 'standardscaler__with_std': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715311004784689"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84688995215311"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimator\n",
    "#model = KNeighborsClassifier(n_neighbors=4, weights=\"uniform\", algorithm=\"auto\", metric = 'minkowski', p = 2)\n",
    "model = KNeighborsClassifier(n_neighbors=4, metric = 'minkowski', p = 2)\n",
    "model.fit(X_train_transform, y_train)\n",
    "X_test_transform = scaler.fit_transform(X_test[['Embarked_cod', 'Pclass', 'Sex_cod']])\n",
    "score_test = model.score(X_test_transform,y_test)\n",
    "score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ex_params = {\n",
    "            'polynomialfeatures__degree' : [2,3,4],\n",
    "            'standardscaler__with_mean' : [True, False],\n",
    "            'standardscaler__with_std' : [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier(random_state=0))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex_pipeline = make_pipeline(PolynomialFeatures(), \n",
    "                           StandardScaler(), \n",
    "                           SGDClassifier(random_state=random_state))\n",
    "grid_ex_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ex = GridSearchCV(grid_ex_pipeline,param_grid=grid_ex_params, cv=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('sgdclassifier',\n",
       "                                        SGDClassifier(random_state=0))]),\n",
       "             param_grid={'polynomialfeatures__degree': [2, 3, 4],\n",
       "                         'standardscaler__with_mean': [True, False],\n",
       "                         'standardscaler__with_std': [True, False]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polynomialfeatures__degree': 3,\n",
       " 'standardscaler__with_mean': False,\n",
       " 'standardscaler__with_std': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715311004784689"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ex.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_grid(X_train, y_train, verbose=False):\n",
    "    grid_dic = {}\n",
    "    if verbose: print(\"randomforestclassifier\", end=\"\")\n",
    "    grid_rf_params = { 'randomforestclassifier__criterion' : [\"gini\", \"entropy\"],\n",
    "                   'randomforestclassifier__n_estimators' : list(range(1,100,10))}\n",
    "    grid_rf_pipeline = make_pipeline( RandomForestClassifier(random_state=random_state))\n",
    "    grid_rf = GridSearchCV(grid_rf_pipeline,param_grid=grid_rf_params, cv=4)\n",
    "    grid_rf.fit(X_train, y_train)\n",
    "    grid_dic['randomforestclassifier'] = grid_rf\n",
    "    if verbose: print(\", kneighborsclassifier\", end=\"\")\n",
    "    grid_knn_params = { 'kneighborsclassifier__n_neighbors': list(range(1,10,1)),\n",
    "                    'kneighborsclassifier__p': list(range(1,10,1)),\n",
    "                    'kneighborsclassifier__metric' : ['minkowski']}\n",
    "    grid_knn_pipeline = make_pipeline( KNeighborsClassifier())\n",
    "    grid_knn = GridSearchCV(grid_knn_pipeline,param_grid=grid_knn_params, cv=4)\n",
    "    grid_knn.fit(X_train, y_train)\n",
    "    grid_dic['kneighborsclassifier'] = grid_knn\n",
    "    if verbose: print(\", decisiontreeclassifier\", end=\"\")\n",
    "    grid_dtc_params = { 'decisiontreeclassifier__criterion' : [\"gini\", \"entropy\"],\n",
    "                    'decisiontreeclassifier__splitter' : [\"best\", \"random\"]}\n",
    "    grid_dtc_pipeline = make_pipeline( DecisionTreeClassifier(random_state=random_state))\n",
    "    grid_dtc = GridSearchCV(grid_dtc_pipeline,param_grid=grid_dtc_params, cv=4)\n",
    "    grid_dtc.fit(X_train, y_train)\n",
    "    grid_dic['decisiontreeclassifier'] = grid_dtc\n",
    "    if verbose: print(\", logisticregression\", end=\"\")\n",
    "    grid_lr_params = { 'logisticregression__solver' : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "                    'logisticregression__penalty' : [None, 'l2', 'l1', 'elasticnet'],\n",
    "                    'logisticregression__fit_intercept' : [True, False]}\n",
    "    # penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
    "    grid_lr_pipeline = make_pipeline( LogisticRegression(random_state=random_state))\n",
    "    grid_lr = GridSearchCV(grid_lr_pipeline,param_grid=grid_lr_params, cv=4)\n",
    "    grid_lr.fit(X_train, y_train)\n",
    "    grid_dic['logisticregression'] = grid_lr\n",
    "    if verbose: print(\"                 DONE\")\n",
    "    return grid_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "104 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.79572678\n",
      " 0.79910516 0.80809397 0.68128106 0.6745344         nan        nan\n",
      " 0.80022624        nan 0.6745344         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.79797903 0.79797903 0.79797903 0.68015493 0.6745344\n",
      "        nan        nan 0.79685796        nan 0.6745344         nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_dic = get_models_grid(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def found_better_config_by_model(X_train, X_test, y_train, y_test, verbose=False):\n",
    "\n",
    "    # on prend un maximum de colonne pour commencer\n",
    "    columns_started = list(X_train.columns)\n",
    "    better_grid_score_dic = {}\n",
    "    better_grid_equals = {}\n",
    "    ever_test = []\n",
    "    \n",
    "    # Modifier l'ordre des colonnes pour trouver encore d'autres configurations pertinentes\n",
    "    # Positionnement de 6 suite aux tests lancés et des premiers résultats\n",
    "    for subset in itertools.permutations(columns_started, 6):\n",
    "        columns = list(subset)\n",
    "            \n",
    "        # a chaque tour, on regardera le meilleur score\n",
    "        while len(columns)>0:\n",
    "            str_col = str(sorted(columns))\n",
    "            if str_col not in ever_test:\n",
    "                grid_dic = get_models_grid(X_train[columns], y_train)\n",
    "                for model_name,grid in grid_dic.items():\n",
    "                    score = grid.score(X_test[columns], y_test)\n",
    "\n",
    "                    model_better_score = better_grid_score_dic.get(model_name, 0)\n",
    "                    model_grig_res = (grid, score, str_col)\n",
    "                    if score > model_better_score:\n",
    "                        model_better_score = score\n",
    "                        better_grid_equals[model_name] = [model_grig_res]\n",
    "                        if verbose:\n",
    "                            print(f\"{model_name} New Best :{round(score,2)} de test, {str_col}, {grid.best_params_}\")\n",
    "                    elif score == model_better_score:\n",
    "                        better_grid_equals[model_name].append(model_grig_res)\n",
    "                        if verbose:\n",
    "                            print(f\"{model_name} Same Best :{round(score,2)} de test, {str_col}, {grid.best_params_}\")\n",
    "\n",
    "                    better_grid_score_dic[model_name] = model_better_score\n",
    "                ever_test.append(str_col)\n",
    "                if verbose>1: print(str_col, \"         DONE\")\n",
    "            # On supprime une colonne\n",
    "            columns.pop()\n",
    "    \n",
    "    return better_grid_score_dic, better_grid_equals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforestclassifier New Best :0.5 de test, ['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group'], {'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__n_estimators': 81}\n",
      "kneighborsclassifier New Best :0.67 de test, ['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group'], {'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 7, 'kneighborsclassifier__p': 1}\n",
      "decisiontreeclassifier New Best :0.82 de test, ['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression New Best :0.94 de test, ['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "logisticregression New Best :0.94 de test, ['Age', 'Pclass', 'Sex_cod', 'Titre_cod', 'group'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "randomforestclassifier New Best :0.53 de test, ['Age', 'Pclass', 'Sex_cod', 'Titre_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 71}\n",
      "kneighborsclassifier New Best :0.75 de test, ['Age', 'Pclass', 'Sex_cod', 'Titre_cod'], {'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 9, 'kneighborsclassifier__p': 1}\n",
      "logisticregression Same Best :0.94 de test, ['Age', 'Pclass', 'Sex_cod', 'Titre_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n",
      "randomforestclassifier New Best :0.56 de test, ['Pclass', 'Sex_cod', 'Titre_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 1}\n",
      "logisticregression New Best :1.0 de test, ['Pclass', 'Sex_cod', 'Titre_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "randomforestclassifier New Best :0.83 de test, ['Pclass', 'Sex_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 1}\n",
      "kneighborsclassifier New Best :1.0 de test, ['Pclass', 'Sex_cod'], {'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 4, 'kneighborsclassifier__p': 1}\n",
      "decisiontreeclassifier New Best :0.83 de test, ['Pclass', 'Sex_cod'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression Same Best :1.0 de test, ['Pclass', 'Sex_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "decisiontreeclassifier New Best :0.83 de test, ['Age', 'Embarked_cod', 'Pclass', 'Sex_cod', 'Titre_cod'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'random'}\n",
      "randomforestclassifier New Best :0.86 de test, ['Age', 'Pclass', 'Sex_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 71}\n",
      "decisiontreeclassifier New Best :0.84 de test, ['Age', 'Pclass', 'Sex_cod'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'random'}\n",
      "randomforestclassifier New Best :0.86 de test, ['Age', 'Embarked_cod', 'Pclass', 'Sex_cod'], {'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__n_estimators': 41}\n",
      "randomforestclassifier New Best :0.96 de test, ['Pclass', 'Sex_cod', 'group'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 21}\n",
      "decisiontreeclassifier New Best :0.98 de test, ['Pclass', 'Sex_cod', 'group'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression Same Best :1.0 de test, ['Pclass', 'Sex_cod', 'deck_cod'], {'logisticregression__fit_intercept': False, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "randomforestclassifier New Best :1.0 de test, ['Sex_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 1}\n",
      "kneighborsclassifier Same Best :1.0 de test, ['Sex_cod'], {'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 9, 'kneighborsclassifier__p': 1}\n",
      "decisiontreeclassifier New Best :1.0 de test, ['Sex_cod'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression Same Best :1.0 de test, ['Sex_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "randomforestclassifier Same Best :1.0 de test, ['Sex_cod', 'Titre_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 1}\n",
      "logisticregression Same Best :1.0 de test, ['Sex_cod', 'Titre_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "logisticregression Same Best :1.0 de test, ['Age', 'Sex_cod', 'Titre_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "logisticregression Same Best :1.0 de test, ['Age', 'Embarked_cod', 'Sex_cod', 'Titre_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "logisticregression Same Best :1.0 de test, ['Age', 'Sex_cod', 'Titre_cod', 'deck_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "logisticregression Same Best :1.0 de test, ['Embarked_cod', 'Sex_cod', 'Titre_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "logisticregression Same Best :1.0 de test, ['Sex_cod', 'Titre_cod', 'deck_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "logisticregression Same Best :1.0 de test, ['Age', 'Sex_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "logisticregression Same Best :1.0 de test, ['Age', 'Sex_cod', 'deck_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n",
      "randomforestclassifier Same Best :1.0 de test, ['Embarked_cod', 'Sex_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 11}\n",
      "kneighborsclassifier Same Best :1.0 de test, ['Embarked_cod', 'Sex_cod'], {'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 1}\n",
      "decisiontreeclassifier Same Best :1.0 de test, ['Embarked_cod', 'Sex_cod'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression Same Best :1.0 de test, ['Embarked_cod', 'Sex_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "logisticregression Same Best :1.0 de test, ['Embarked_cod', 'Sex_cod', 'deck_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "randomforestclassifier Same Best :1.0 de test, ['Sex_cod', 'deck_cod'], {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 11}\n",
      "decisiontreeclassifier Same Best :1.0 de test, ['Sex_cod', 'deck_cod'], {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression Same Best :1.0 de test, ['Sex_cod', 'deck_cod'], {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "better_grid_score_dic, better_grid_equals = found_better_config_by_model(X_train, X_test, y_train, y_test, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier': 1.0,\n",
       " 'kneighborsclassifier': 1.0,\n",
       " 'decisiontreeclassifier': 1.0,\n",
       " 'logisticregression': 1.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_grid_score_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforestclassifier\n",
      "['Sex_cod']{'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 1}\n",
      "['Sex_cod', 'Titre_cod']{'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 1}\n",
      "['Embarked_cod', 'Sex_cod']{'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 11}\n",
      "['Sex_cod', 'deck_cod']{'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__n_estimators': 11}\n",
      "kneighborsclassifier\n",
      "['Pclass', 'Sex_cod']{'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 4, 'kneighborsclassifier__p': 1}\n",
      "['Sex_cod']{'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 9, 'kneighborsclassifier__p': 1}\n",
      "['Embarked_cod', 'Sex_cod']{'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 1}\n",
      "decisiontreeclassifier\n",
      "['Sex_cod']{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "['Embarked_cod', 'Sex_cod']{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "['Sex_cod', 'deck_cod']{'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__splitter': 'best'}\n",
      "logisticregression\n",
      "['Pclass', 'Sex_cod', 'Titre_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Pclass', 'Sex_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "['Pclass', 'Sex_cod', 'deck_cod']{'logisticregression__fit_intercept': False, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "['Sex_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "['Sex_cod', 'Titre_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "['Age', 'Sex_cod', 'Titre_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Age', 'Embarked_cod', 'Sex_cod', 'Titre_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Age', 'Sex_cod', 'Titre_cod', 'deck_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Embarked_cod', 'Sex_cod', 'Titre_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Sex_cod', 'Titre_cod', 'deck_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Age', 'Sex_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "['Age', 'Sex_cod', 'deck_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n",
      "['Embarked_cod', 'Sex_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "['Embarked_cod', 'Sex_cod', 'deck_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "['Sex_cod', 'deck_cod']{'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Affichage des meilleures configurations et colonnes\n",
    "for k in better_grid_equals.keys():\n",
    "    v = better_grid_equals[k]\n",
    "    print(k)\n",
    "    for val in v:\n",
    "        print(val[-1], end=\"\")\n",
    "        if isinstance(val[0], GridSearchCV):\n",
    "            print(val[0].best_params_, end=\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Avec Grid Search CV j'ai les résultats :</mark>\n",
    "\n",
    "```Python\n",
    "randomforestclassifier = 1.0\n",
    "kneighborsclassifier = 1.0\n",
    "decisiontreeclassifier = 1.0\n",
    "logisticregression = 1.0\n",
    "```\n",
    "Avec les paramètres :\n",
    "\n",
    "```Python\n",
    "# logisticregression\n",
    "['Pclass', 'Sex_cod', 'Titre_cod'],              {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Pclass', 'Sex_cod'],                           {'fit_intercept': True, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "['Pclass', 'Sex_cod', 'deck_cod'],               {'fit_intercept': False, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "['Sex_cod'],                                     {'fit_intercept': True, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "['Sex_cod', 'Titre_cod'],                        {'fit_intercept': True, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "['Age', 'Sex_cod', 'Titre_cod'],                 {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Age', 'Embarked_cod', 'Sex_cod', 'Titre_cod'], {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Age', 'Sex_cod', 'Titre_cod', 'deck_cod'],     {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Embarked_cod', 'Sex_cod', 'Titre_cod'],        {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Sex_cod', 'Titre_cod', 'deck_cod'],            {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Age', 'Sex_cod'],                              {'fit_intercept': True, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "['Age', 'Sex_cod', 'deck_cod'],                  {'fit_intercept': True, 'penalty': 'l2', 'solver': 'sag'}\n",
    "['Embarked_cod', 'Sex_cod'],                     {'fit_intercept': True, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "['Embarked_cod', 'Sex_cod', 'deck_cod'],         {'fit_intercept': True, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "['Sex_cod', 'deck_cod'],                         {'fit_intercept': True, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "\n",
    "# randomforestclassifier :\n",
    "['Sex_cod'],                 {'criterion': 'gini', 'n_estimators': 1}\n",
    "['Sex_cod', 'Titre_cod'],    {'criterion': 'gini', 'n_estimators': 1}\n",
    "['Embarked_cod', 'Sex_cod'], {'criterion': 'gini', 'n_estimators': 11}\n",
    "['Sex_cod', 'deck_cod'],     {'criterion': 'gini', 'n_estimators': 11}\n",
    "\n",
    "# kneighborsclassifier:\n",
    "['Pclass', 'Sex_cod'],       {'metric': 'minkowski', 'n_neighbors': 4, 'p': 1}\n",
    "['Sex_cod'],                 {'metric': 'minkowski', 'n_neighbors': 9, 'p': 1}\n",
    "['Embarked_cod', 'Sex_cod'], {'metric': 'minkowski', 'n_neighbors': 5, 'p': 1}\n",
    "\n",
    "# decisiontreeclassifier:\n",
    "['Sex_cod'],                 {'criterion': 'gini', 'splitter': 'best'}\n",
    "['Embarked_cod', 'Sex_cod'], {'criterion': 'gini', 'splitter': 'best'}\n",
    "['Sex_cod', 'deck_cod'],     {'criterion': 'gini', 'splitter': 'best'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('randomforestclassifier',\n",
      "                 RandomForestClassifier(random_state=0))])\n",
      "GridSearchCV(cv=4,\n",
      "             estimator=Pipeline(steps=[('randomforestclassifier',\n",
      "                                        RandomForestClassifier(random_state=0))]),\n",
      "             param_grid={'randomforestclassifier__criterion': ['gini',\n",
      "                                                               'entropy'],\n",
      "                         'randomforestclassifier__n_estimators': [1, 11, 21, 31,\n",
      "                                                                  41, 51, 61,\n",
      "                                                                  71, 81, 91]})\n"
     ]
    }
   ],
   "source": [
    "grid_rf_params = { 'randomforestclassifier__criterion' : [\"gini\", \"entropy\"],\n",
    "                   'randomforestclassifier__n_estimators' : list(range(1,100,10))}\n",
    "grid_rf_pipeline = make_pipeline( RandomForestClassifier(random_state=random_state))\n",
    "print(grid_rf_pipeline)\n",
    "grid_rf = GridSearchCV(grid_rf_pipeline,param_grid=grid_rf_params, cv=4)\n",
    "print(grid_rf.fit(X_train, y_train))\n",
    "grid_dic['randomforestclassifier'] = grid_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('kneighborsclassifier', KNeighborsClassifier())])\n",
      "GridSearchCV(cv=4,\n",
      "             estimator=Pipeline(steps=[('kneighborsclassifier',\n",
      "                                        KNeighborsClassifier())]),\n",
      "             param_grid={'kneighborsclassifier__metric': ['minkowski'],\n",
      "                         'kneighborsclassifier__n_neighbors': [1, 2, 3, 4, 5, 6,\n",
      "                                                               7, 8, 9],\n",
      "                         'kneighborsclassifier__p': [1, 2, 3, 4, 5, 6, 7, 8,\n",
      "                                                     9]})\n"
     ]
    }
   ],
   "source": [
    "grid_knn_params = { 'kneighborsclassifier__n_neighbors': list(range(1,10,1)),\n",
    "                    'kneighborsclassifier__p': list(range(1,10,1)),\n",
    "                    'kneighborsclassifier__metric' : ['minkowski']}\n",
    "grid_knn_pipeline = make_pipeline( KNeighborsClassifier())\n",
    "print(grid_knn_pipeline)\n",
    "grid_knn = GridSearchCV(grid_knn_pipeline,param_grid=grid_knn_params, cv=4)\n",
    "print(grid_knn.fit(X_train, y_train))\n",
    "grid_dic['kneighborsclassifier'] = grid_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(random_state=0))])\n",
      "GridSearchCV(cv=4,\n",
      "             estimator=Pipeline(steps=[('decisiontreeclassifier',\n",
      "                                        DecisionTreeClassifier(random_state=0))]),\n",
      "             param_grid={'decisiontreeclassifier__criterion': ['gini',\n",
      "                                                               'entropy'],\n",
      "                         'decisiontreeclassifier__splitter': ['best',\n",
      "                                                              'random']})\n"
     ]
    }
   ],
   "source": [
    "grid_dtc_params = { 'decisiontreeclassifier__criterion' : [\"gini\", \"entropy\"],\n",
    "                    'decisiontreeclassifier__splitter' : [\"best\", \"random\"]}\n",
    "grid_dtc_pipeline = make_pipeline( DecisionTreeClassifier(random_state=random_state))\n",
    "print(grid_dtc_pipeline)\n",
    "grid_dtc = GridSearchCV(grid_dtc_pipeline,param_grid=grid_dtc_params, cv=4)\n",
    "print(grid_dtc.fit(X_train, y_train))\n",
    "grid_dic['decisiontreeclassifier'] = grid_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('logisticregression', LogisticRegression(random_state=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "104 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got None.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.79572678\n",
      " 0.79910516 0.80809397 0.68128106 0.6745344         nan        nan\n",
      " 0.80022624        nan 0.6745344         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.79797903 0.79797903 0.79797903 0.68015493 0.6745344\n",
      "        nan        nan 0.79685796        nan 0.6745344         nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=4,\n",
      "             estimator=Pipeline(steps=[('logisticregression',\n",
      "                                        LogisticRegression(random_state=0))]),\n",
      "             param_grid={'logisticregression__fit_intercept': [True, False],\n",
      "                         'logisticregression__penalty': [None, 'l2', 'l1',\n",
      "                                                         'elasticnet'],\n",
      "                         'logisticregression__solver': ['newton-cg', 'lbfgs',\n",
      "                                                        'liblinear', 'sag',\n",
      "                                                        'saga']})\n"
     ]
    }
   ],
   "source": [
    "grid_lr_params = { 'logisticregression__solver' : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "                    'logisticregression__penalty' : [None, 'l2', 'l1', 'elasticnet'],\n",
    "                    'logisticregression__fit_intercept' : [True, False]}\n",
    "# penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
    "grid_lr_pipeline = make_pipeline( LogisticRegression(random_state=random_state))\n",
    "print(grid_lr_pipeline)\n",
    "grid_lr = GridSearchCV(grid_lr_pipeline,param_grid=grid_lr_params, cv=4)\n",
    "print(grid_lr.fit(X_train, y_train))\n",
    "grid_dic['logisticregression'] = grid_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39 randomforestclassifier Best params: {'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__n_estimators': 11}\n",
      "0.656 kneighborsclassifier Best params: {'kneighborsclassifier__metric': 'minkowski', 'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 1}\n",
      "0.818 decisiontreeclassifier Best params: {'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__splitter': 'best'}\n",
      "0.943 logisticregression Best params: {'logisticregression__fit_intercept': True, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "dic_model_score = {}\n",
    "for model_name,grid in grid_dic.items():\n",
    "    score = grid.score(X_test, y_test)\n",
    "    dic_model_score[model_name] = score\n",
    "    print(round(score,3), model_name, \"Best params:\",grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La meilleure configuration sur la base du score de test est (exécution = nouveau train et nouveau test) :\n",
    "* Exécution 1: 0.89 de test <=> 0.85 de train, KNN = 4 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
    "* Exécution 2: 0.87 de test <=> 0.82 de train, KNN= 5 avec les colonnes : ['Pclass', 'sex_cod', 'title_cod', 'embarked_cod']\n",
    "* Exécution 3: \n",
    "   * 0.82 de test <=> 0.86 de train, KNN = 2 :['Pclass', 'sex_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
    "   * 0.82 de test <=> 0.85 de train, KNN = 4 :['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']\n",
    "   * 0.82 de test <=> 0.82 de train, KNN = 3 :['Pclass', 'sex_cod', 'family_on_board', 'embarked_cod']\n",
    "   * 0.82 de test <=> 0.86 de train, KNN = 4 :['Pclass', 'title_cod', 'embarked_cod', 'deck_cod']\n",
    "* Exécution 4:\n",
    "   * 0.9 de test <=> 0.83 de train, KNN= 7 avec les colonnes : ['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde du model car j'aurai du mal à avoir un meilleur score que 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex_cod', 'Titre_cod', 'Age', 'group', 'Fare',\n",
       "       'Embarked_cod', 'deck_cod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.92 de test <=> 0.8 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "Same Best :0.92 de test <=> 0.8 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "Same Best :0.92 de test <=> 0.8 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "Same Best :0.92 de test <=> 0.8 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.94 de test <=> 0.81 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.94 de test <=> 0.81 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Age', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.94 de test <=> 0.8 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Age', 'Pclass', 'Sex_cod', 'Titre_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.99 de test <=> 0.78 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=False, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=False, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=newton-cg,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=lbfgs,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=sag,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "LogisticReg Score 1.0 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=liblinear,random_state=0 :['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "[0]Logistic Regression Training Accuracy: 1.0 ( train: 0.7867564534231201 ) with: ['Pclass', 'Sex_cod', 'Titre_cod']\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "log, log_better_columns, log_test_res, log_better_score, log_better_score_train = logisticRegression_found_better_full(X_train, X_test, y_train, y_test, random_state=0, plot=False, verbose=1)\n",
    "print('[0]Logistic Regression Training Accuracy:', log_better_score, \"( train:\", log_better_score_train, \") with:\", log_better_columns)\n",
    "#print(log_test_res[log_better_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.63 de test <=> 0.77 de train, KNN = 8 :['Pclass', 'Sex_cod', 'Titre_cod', 'Age', 'group', 'Fare']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :1.0 de test <=> 0.79 de train, KNN = 2 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, KNN = 4 :['Embarked_cod', 'Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, KNN = 1 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, KNN = 1 :['Sex_cod', 'Titre_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, KNN = 1 :['Embarked_cod', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, KNN = 7 :['Sex_cod', 'deck_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "KNN Score 1.0 de test <=> 0.79 de train, KNN= 2 avec les colonnes : ['Pclass', 'Sex_cod']\n",
      "[1]K Nearest Neighbor Training Accuracy: 1.0 ( train: 0.7867564534231201 ) with: ['Pclass', 'Sex_cod']\n"
     ]
    }
   ],
   "source": [
    "# KNeighborsClassifier Method of neighbors class to use Nearest Neighbor algorithm\n",
    "knn, knn_better_columns, knn_test_res, knn_better_score, knn_better_score_train = knn_found_better_config(X_train,X_test, y_train, y_test, verbose=1)\n",
    "print('[1]K Nearest Neighbor Training Accuracy:', knn_better_score, \"( train:\", knn_better_score_train, \") with:\", knn_better_columns)\n",
    "#print(knn_test_res[knn_better_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.82 de test <=> 0.99 de train, param = criterion=gini, splitter=best,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.83 de test <=> 0.79 de train, param = criterion=gini, splitter=best,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :0.83 de test <=> 0.79 de train, param = criterion=gini, splitter=random,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :0.83 de test <=> 0.79 de train, param = criterion=entropy, splitter=best,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :0.83 de test <=> 0.79 de train, param = criterion=entropy, splitter=random,random_state=0 :['Pclass', 'Sex_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.83 de test <=> 0.92 de train, param = criterion=gini, splitter=random,random_state=0 :['Age', 'Embarked_cod', 'Pclass', 'Sex_cod', 'Titre_cod']\n",
      "Same Best :0.83 de test <=> 0.92 de train, param = criterion=gini, splitter=best,random_state=0 :['Age', 'Embarked_cod', 'Pclass', 'Sex_cod', 'Titre_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.84 de test <=> 0.89 de train, param = criterion=gini, splitter=random,random_state=0 :['Age', 'Pclass', 'Sex_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.85 de test <=> 0.91 de train, param = criterion=gini, splitter=best,random_state=0 :['Age', 'Embarked_cod', 'Pclass', 'Sex_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.98 de test <=> 0.81 de train, param = criterion=gini, splitter=best,random_state=0 :['Pclass', 'Sex_cod', 'group']\n",
      "Same Best :0.98 de test <=> 0.81 de train, param = criterion=gini, splitter=random,random_state=0 :['Pclass', 'Sex_cod', 'group']\n",
      "Same Best :0.98 de test <=> 0.81 de train, param = criterion=entropy, splitter=best,random_state=0 :['Pclass', 'Sex_cod', 'group']\n",
      "Same Best :0.98 de test <=> 0.81 de train, param = criterion=entropy, splitter=random,random_state=0 :['Pclass', 'Sex_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=best,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=random,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=entropy, splitter=best,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=entropy, splitter=random,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=best,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=random,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=entropy, splitter=best,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=entropy, splitter=random,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=best,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=random,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=entropy, splitter=best,random_state=0 :['Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = criterion=entropy, splitter=random,random_state=0 :['Sex_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "DecisionTree Score 1.0 de test <=> 0.79 de train, param = criterion=gini, splitter=best,random_state=0 :['Sex_cod']\n",
      "[2]Decision Tree Classifier Training Accuracy: 1.0 ( train: 0.7867564534231201 ) with: ['Sex_cod']\n"
     ]
    }
   ],
   "source": [
    "# Arbre de décision\n",
    "tree, tree_better_columns, tree_test_res, tree_better_score, tree_better_score_train = decisionTree_found_best(X_train, X_test, y_train, y_test, random_state=0, plot=False, verbose=True)\n",
    "print('[2]Decision Tree Classifier Training Accuracy:', tree_better_score, \"( train:\", tree_better_score_train, \") with:\", tree_better_columns)\n",
    "#print(tree_test_res[tree_better_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.44 de test <=> 0.92 de train, param = n_estimators=1, criterion=gini,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.45 de test <=> 0.92 de train, param = n_estimators=1, criterion=entropy,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.47 de test <=> 0.98 de train, param = n_estimators=11, criterion=entropy,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.48 de test <=> 0.99 de train, param = n_estimators=51, criterion=gini,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.5 de test <=> 0.99 de train, param = n_estimators=61, criterion=gini,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.52 de test <=> 0.99 de train, param = n_estimators=61, criterion=entropy,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.53 de test <=> 0.99 de train, param = n_estimators=71, criterion=entropy,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "Same Best :0.53 de test <=> 0.99 de train, param = n_estimators=91, criterion=entropy,random_state=0 :['Age', 'Fare', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.73 de test <=> 0.9 de train, param = n_estimators=1, criterion=gini,random_state=0 :['Age', 'Pclass', 'Sex_cod', 'Titre_cod', 'group']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.79 de test <=> 0.87 de train, param = n_estimators=1, criterion=entropy,random_state=0 :['Age', 'Pclass', 'Sex_cod', 'Titre_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.83 de test <=> 0.79 de train, param = n_estimators=1, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :0.83 de test <=> 0.79 de train, param = n_estimators=1, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=31, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=31, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=41, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=41, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=51, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=51, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=61, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=61, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=71, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=71, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=1, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=1, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=21, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=21, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=31, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=31, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=41, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=41, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=51, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=51, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=61, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=61, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=71, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=71, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=1, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=1, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=1, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=1, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=21, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=21, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=31, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=31, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=41, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=41, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=51, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=51, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=61, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=61, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=71, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=71, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=81, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "Same Best :1.0 de test <=> 0.79 de train, param = n_estimators=91, criterion=entropy,random_state=0 :['Pclass', 'Sex_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "RandomForest Score 1.0 de test <=> 0.79 de train, param = n_estimators=11, criterion=gini,random_state=0 :['Pclass', 'Sex_cod']\n",
      "[3]Random Forest Classifier Training Accuracy: 1.0 ( train: 0.7867564534231201 ) with: ['Pclass', 'Sex_cod']\n"
     ]
    }
   ],
   "source": [
    "# Forêt aléatoire\n",
    "forest, forest_better_columns, forest_test_res, forest_better_score, forest_better_score_train = randomForest_found_best(X_train, X_test, y_train, y_test, random_state=0, plot=False, verbose=True)\n",
    "print('[3]Random Forest Classifier Training Accuracy:', forest_better_score, \"( train:\", forest_better_score_train, \") with:\", forest_better_columns)\n",
    "#print(forest_test_res[forest_better_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 for test ( 0.79 for train) => Logistic Regression, with: ['Pclass', 'Sex_cod', 'Titre_cod']\n",
      "1.0 for test ( 0.79 for train) => K Nearest Neighbor, with: ['Pclass', 'Sex_cod']\n",
      "1.0 for test ( 0.79 for train) => Decision Tree, with: ['Sex_cod']\n",
      "1.0 for test ( 0.79 for train) => Random Forest, with: ['Pclass', 'Sex_cod']\n"
     ]
    }
   ],
   "source": [
    "print(log_better_score, \"for test (\", round(log_better_score_train, 2), \"for train) => Logistic Regression, with:\", log_better_columns)\n",
    "print(knn_better_score, \"for test (\",  round(knn_better_score_train, 2), \"for train) => K Nearest Neighbor, with:\", knn_better_columns)\n",
    "print(tree_better_score, \"for test (\",  round(tree_better_score_train, 2), \"for train) => Decision Tree, with:\", tree_better_columns)\n",
    "print(forest_better_score, \"for test (\",  round(forest_better_score_train, 2), \"for train) => Random Forest, with:\", forest_better_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X]Support Vector Machine (Linear Classifier) Training Accuracy: 1.0 ( train: 0.7867564534231201 )\n",
      "[X]Support Vector Machine (RBF Classifier) Training Accuracy: 0.645933014354067 ( train: 0.6902356902356902 )\n",
      "[X]Gaussian Naive Bayes Training Accuracy: 0.8086124401913876 ( train: 0.7867564534231201 )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(kernel='linear', random_state=0), SVC(random_state=0), GaussianNB())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_lin, svc_rbf, gauss = best_other_model(X_train,y_train, X_test, y_test, verbose=False)\n",
    "svc_lin, svc_rbf, gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11972/2334858804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     print(better_knn_model, round(score_test, 2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbetter_knn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetter_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetter_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_found_better_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# Sauvegarde du meilleur modele\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# current date and time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\WORK\\wokspace-simplon3\\simplon\\projets\\titanic\\function.py\u001b[0m in \u001b[0;36mknn_found_better_config\u001b[1;34m(X_train, X_test, y_train, y_test, knn_min, knn_max, plot)\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[0mstr_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstr_col\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mever_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetter_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_found_better_neigbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[1;31m# on stocke le résultat pour plus tard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\WORK\\wokspace-simplon3\\simplon\\projets\\titanic\\function.py\u001b[0m in \u001b[0;36mknn_found_better_neigbors\u001b[1;34m(x, y, x_test, y_test, knn_min, knn_max, plot)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m         \u001b[0mscore_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mscore_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    712\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# better_knn_model = None\n",
    "# if model_knn_save_exist:\n",
    "#     better_knn_model = load(file_path+ model_knn_save_path)\n",
    "#     score_test = better_knn_model.score(X_test[['Pclass', 'Sex_cod', 'Titre_cod', 'Embarked_cod', 'deck_cod']],y_test)\n",
    "#     print(better_knn_model, round(score_test, 2))\n",
    "# else:\n",
    "better_knn_model, better_columns, test_res, better_score = knn_found_better_config(X_train, X_test, y_train, y_test, knn_min=1, knn_max=10, plot=False)\n",
    "# Sauvegarde du meilleur modele\n",
    "now = datetime.now() # current date and time\n",
    "date_time = now.strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "# Attention, il faudra mettre à jour les colonnes correspondantes dans le premier if en cas de modification du model\n",
    "dump(better_knn_model, file_path+'Titanic_model_saved_score_'+str(round(better_score,2))+'_' + date_time + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "titres_dic = {\"Mr\" : 7, \"Miss\" : 6, \"Mrs\" : 8, \"Master\" : 5, \"Dr\" : 2, \"Rev\" : 6}\n",
    "col = ['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss\n",
      "['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod'], [proba]\n",
      "[3, 1, 6, 1, 3] = [0] [[0.71428571 0.28571429]]\n",
      "[2, 1, 6, 0, 6] = [0] [[0.85714286 0.14285714]]\n",
      "[1, 1, 6, 0, 1] = [1] [[0.14285714 0.85714286]]\n",
      "Mrs\n",
      "['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod'], [proba]\n",
      "[3, 1, 8, 1, 6] = [0] [[1. 0.]]\n",
      "[2, 1, 8, 0, 5] = [0] [[0.57142857 0.42857143]]\n",
      "[1, 1, 8, -1, 3] = [1] [[0.14285714 0.85714286]]\n",
      "Mr\n",
      "['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod'], [proba]\n",
      "[3, 0, 7, 2, 1] = [0] [[1. 0.]]\n",
      "[2, 0, 7, 1, 2] = [0] [[0.85714286 0.14285714]]\n",
      "[1, 0, 7, -1, 1] = [1] [[0. 1.]]\n",
      "Master\n",
      "['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod'], [proba]\n",
      "[3, 0, 5, 2, 3] = [1] [[0.42857143 0.57142857]]\n",
      "[2, 0, 5, 1, 1] = [1] [[0. 1.]]\n",
      "[1, 0, 5, 1, 2] = [1] [[0.28571429 0.71428571]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int64), array([[0.28571429, 0.71428571]]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Miss\")\n",
    "print(f\"{col}, [proba]\")\n",
    "knn_predire_survie(better_knn_model, pclass=3, sex=1, age=randint(0, 80), title=titres_dic[\"Miss\"])\n",
    "knn_predire_survie(better_knn_model, pclass=2, sex=1, age=randint(0, 80), title=titres_dic[\"Miss\"])\n",
    "knn_predire_survie(better_knn_model, pclass=1, sex=1, age=randint(0, 80), title=titres_dic[\"Miss\"])\n",
    "print(\"Mrs\")\n",
    "print(f\"{col}, [proba]\")\n",
    "knn_predire_survie(better_knn_model, pclass=3, sex=1, age=randint(15, 80), title=titres_dic[\"Mrs\"])\n",
    "knn_predire_survie(better_knn_model, pclass=2, sex=1, age=randint(15, 80), title=titres_dic[\"Mrs\"])\n",
    "knn_predire_survie(better_knn_model, pclass=1, sex=1, age=randint(15, 80), title=titres_dic[\"Mrs\"])\n",
    "print(\"Mr\")\n",
    "print(f\"{col}, [proba]\")\n",
    "knn_predire_survie(better_knn_model, pclass=3, sex=0, age=randint(0, 80), title=titres_dic[\"Mr\"])\n",
    "knn_predire_survie(better_knn_model, pclass=2, sex=0, age=randint(0, 80), title=titres_dic[\"Mr\"])\n",
    "knn_predire_survie(better_knn_model, pclass=1, sex=0, age=randint(0, 80), title=titres_dic[\"Mr\"])\n",
    "print(\"Master\")\n",
    "print(f\"{col}, [proba]\")\n",
    "knn_predire_survie(better_knn_model, pclass=3, sex=0, age=randint(20, 80), title=titres_dic[\"Master\"])\n",
    "knn_predire_survie(better_knn_model, pclass=2, sex=0, age=randint(20, 80), title=titres_dic[\"Master\"])\n",
    "knn_predire_survie(better_knn_model, pclass=1, sex=0, age=randint(20, 80), title=titres_dic[\"Master\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La meilleure configuration pour ce model et le meilleur score :     \n",
    "* 0.84 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Age', 'Pclass', 'embarked_cod', 'sex_cod']\n",
    "* 0.84 de test <=> 0.79 de train, param = penalty=none, fit_intercept=True, solver=saga,random_state=0 :['Age', 'Pclass', 'embarked_cod', 'sex_cod']\n",
    "* 0.84 de test <=> 0.79 de train, param = penalty=l2, fit_intercept=True, solver=saga,random_state=0 :['Age', 'Pclass', 'embarked_cod', 'sex_cod']\n",
    "* 0.84 de test <=> 0.79 de train, param = penalty=l1, fit_intercept=True, solver=saga,random_state=0 :['Age', 'Pclass', 'embarked_cod', 'sex_cod']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomForestClassifier\n",
    "j'ai essayé le random forest sur ton fichier, j'ai eu un score de 0,85  et en ajoutant une colonne titre comme 'Countess,Major ...' j'arrive à avoir un score de 0,86\n",
    "oui, avec les variables catégorielles comme le deck par exemple tu peux utiliser le from sklearn.preprocessing import OrdinalEncoder pour qu'elle soit exploitable par l'algorithme de machine learning\n",
    "* KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex_cod         0.317152\n",
       "deck_cod        0.226847\n",
       "title_cod       0.206376\n",
       "Pclass          0.159743\n",
       "embarked_cod    0.089883\n",
       "dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "columns_logistic = ['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']\n",
    "\n",
    "model_forest = RandomForestClassifier(n_estimators=100,random_state=random_state)\n",
    "model_forest.fit(X_train[columns_logistic],y_train)\n",
    "pd.Series(model_forest.feature_importances_,index=columns_logistic).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8770949720670391"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest.score(X_test[columns_logistic], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "columns_decision_tree_started = ['Pclass', 'sex_cod', 'title_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
    "\n",
    "model_decision_tree=DecisionTreeClassifier()\n",
    "model_decision_tree.fit(X_train[columns_decision_tree_started],y_train)\n",
    "print(model_decision_tree.score(X_test[columns_decision_tree_started], y_test))\n",
    "prediction=model_decision_tree.predict(X_test[columns_decision_tree_started])\n",
    "# print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "une question à réfléchir pourquoi OrdinalEncoder()\n",
    " pas LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_25944/3596157890.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_25944/3596157890.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    juste to fail\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "juste to fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.75 de test <=> 0.83 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'family_on_board', 'Fare']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.83 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'family_on_board']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.84 de test <=> 0.81 de train, KNN = 7 :['Pclass', 'sex_cod', 'title_cod', 'Age']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.85 de test <=> 0.78 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "0.84 de test <=> 0.77 de train, KNN = 1 :['Pclass', 'sex_cod']\n",
      "0.69 de test <=> 0.68 de train, KNN = 1 :['Pclass']\n",
      "0.81 de test <=> 0.85 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.84 de test <=> 0.82 de train, KNN = 5 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.75 de test <=> 0.83 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'Fare']\n",
      "0.75 de test <=> 0.83 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'Fare', 'deck_cod']\n",
      "0.83 de test <=> 0.82 de train, KNN = 4 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'embarked_cod']\n",
      "0.83 de test <=> 0.83 de train, KNN = 5 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.82 de train, KNN = 5 :['Pclass', 'sex_cod', 'title_cod', 'Age', 'deck_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.88 de test <=> 0.82 de train, KNN = 7 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "0.82 de test <=> 0.79 de train, KNN = 9 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'Fare']\n",
      "0.79 de test <=> 0.8 de train, KNN = 6 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.83 de test <=> 0.88 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.87 de test <=> 0.81 de train, KNN = 6 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'embarked_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.89 de test <=> 0.82 de train, KNN = 9 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "0.87 de test <=> 0.83 de train, KNN = 7 :['Pclass', 'sex_cod', 'title_cod', 'family_on_board', 'deck_cod']\n",
      "0.83 de test <=> 0.89 de train, KNN = 1 :['Pclass', 'sex_cod', 'title_cod', 'Fare']\n",
      "0.81 de test <=> 0.79 de train, KNN = 6 :['Pclass', 'sex_cod', 'title_cod', 'Fare', 'embarked_cod']\n",
      "0.8 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.82 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'title_cod', 'Fare', 'deck_cod']\n",
      "0.86 de test <=> 0.8 de train, KNN = 7 :['Pclass', 'sex_cod', 'title_cod', 'embarked_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "New Best :0.9 de test <=> 0.83 de train, KNN = 7 :['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "0.87 de test <=> 0.81 de train, KNN = 6 :['Pclass', 'sex_cod', 'title_cod', 'deck_cod']\n",
      "0.84 de test <=> 0.81 de train, KNN = 8 :['Pclass', 'sex_cod', 'Age']\n",
      "0.8 de test <=> 0.84 de train, KNN = 4 :['Pclass', 'sex_cod', 'Age', 'family_on_board']\n",
      "0.77 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'family_on_board', 'Fare']\n",
      "0.77 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.85 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.78 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.82 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.83 de test <=> 0.79 de train, KNN = 6 :['Pclass', 'sex_cod', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.75 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'Fare']\n",
      "0.77 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'Fare', 'embarked_cod']\n",
      "0.78 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.78 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'sex_cod', 'Age', 'Fare', 'deck_cod']\n",
      "0.83 de test <=> 0.81 de train, KNN = 4 :['Pclass', 'sex_cod', 'Age', 'embarked_cod']\n",
      "0.83 de test <=> 0.79 de train, KNN = 9 :['Pclass', 'sex_cod', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.81 de test <=> 0.81 de train, KNN = 5 :['Pclass', 'sex_cod', 'Age', 'deck_cod']\n",
      "0.85 de test <=> 0.8 de train, KNN = 7 :['Pclass', 'sex_cod', 'family_on_board']\n",
      "0.81 de test <=> 0.9 de train, KNN = 1 :['Pclass', 'sex_cod', 'family_on_board', 'Fare']\n",
      "0.8 de test <=> 0.9 de train, KNN = 1 :['Pclass', 'sex_cod', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.8 de test <=> 0.96 de train, KNN = 1 :['Pclass', 'sex_cod', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.82 de test <=> 0.95 de train, KNN = 1 :['Pclass', 'sex_cod', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.85 de test <=> 0.79 de train, KNN = 9 :['Pclass', 'sex_cod', 'family_on_board', 'embarked_cod']\n",
      "0.85 de test <=> 0.82 de train, KNN = 6 :['Pclass', 'sex_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.84 de test <=> 0.8 de train, KNN = 9 :['Pclass', 'sex_cod', 'family_on_board', 'deck_cod']\n",
      "0.83 de test <=> 0.85 de train, KNN = 3 :['Pclass', 'sex_cod', 'Fare']\n",
      "0.8 de test <=> 0.88 de train, KNN = 1 :['Pclass', 'sex_cod', 'Fare', 'embarked_cod']\n",
      "0.8 de test <=> 0.9 de train, KNN = 2 :['Pclass', 'sex_cod', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.82 de test <=> 0.9 de train, KNN = 2 :['Pclass', 'sex_cod', 'Fare', 'deck_cod']\n",
      "0.87 de test <=> 0.8 de train, KNN = 6 :['Pclass', 'sex_cod', 'embarked_cod']\n",
      "0.87 de test <=> 0.81 de train, KNN = 8 :['Pclass', 'sex_cod', 'embarked_cod', 'deck_cod']\n",
      "0.83 de test <=> 0.79 de train, KNN = 9 :['Pclass', 'sex_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.78 de train, KNN = 3 :['Pclass', 'title_cod']\n",
      "0.82 de test <=> 0.8 de train, KNN = 7 :['Pclass', 'title_cod', 'Age']\n",
      "0.77 de test <=> 0.91 de train, KNN = 1 :['Pclass', 'title_cod', 'Age', 'family_on_board']\n",
      "0.75 de test <=> 0.75 de train, KNN = 9 :['Pclass', 'title_cod', 'Age', 'family_on_board', 'Fare']\n",
      "0.76 de test <=> 0.76 de train, KNN = 6 :['Pclass', 'title_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.76 de test <=> 0.84 de train, KNN = 2 :['Pclass', 'title_cod', 'Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.76 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'title_cod', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.8 de test <=> 0.96 de train, KNN = 1 :['Pclass', 'title_cod', 'Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.79 de test <=> 0.81 de train, KNN = 4 :['Pclass', 'title_cod', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.75 de test <=> 0.75 de train, KNN = 7 :['Pclass', 'title_cod', 'Age', 'Fare']\n",
      "0.77 de test <=> 0.75 de train, KNN = 7 :['Pclass', 'title_cod', 'Age', 'Fare', 'embarked_cod']\n",
      "0.76 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'title_cod', 'Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.77 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'title_cod', 'Age', 'Fare', 'deck_cod']\n",
      "0.79 de test <=> 0.9 de train, KNN = 1 :['Pclass', 'title_cod', 'Age', 'embarked_cod']\n",
      "0.78 de test <=> 0.95 de train, KNN = 1 :['Pclass', 'title_cod', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.79 de test <=> 0.94 de train, KNN = 1 :['Pclass', 'title_cod', 'Age', 'deck_cod']\n",
      "0.88 de test <=> 0.82 de train, KNN = 7 :['Pclass', 'title_cod', 'family_on_board']\n",
      "0.79 de test <=> 0.91 de train, KNN = 1 :['Pclass', 'title_cod', 'family_on_board', 'Fare']\n",
      "0.78 de test <=> 0.78 de train, KNN = 9 :['Pclass', 'title_cod', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.8 de test <=> 0.86 de train, KNN = 3 :['Pclass', 'title_cod', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.81 de test <=> 0.96 de train, KNN = 1 :['Pclass', 'title_cod', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.86 de test <=> 0.8 de train, KNN = 6 :['Pclass', 'title_cod', 'family_on_board', 'embarked_cod']\n",
      "0.87 de test <=> 0.82 de train, KNN = 9 :['Pclass', 'title_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.8 de train, KNN = 9 :['Pclass', 'title_cod', 'family_on_board', 'deck_cod']\n",
      "0.83 de test <=> 0.89 de train, KNN = 1 :['Pclass', 'title_cod', 'Fare']\n",
      "0.78 de test <=> 0.82 de train, KNN = 3 :['Pclass', 'title_cod', 'Fare', 'embarked_cod']\n",
      "0.78 de test <=> 0.88 de train, KNN = 2 :['Pclass', 'title_cod', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.8 de test <=> 0.95 de train, KNN = 1 :['Pclass', 'title_cod', 'Fare', 'deck_cod']\n",
      "0.86 de test <=> 0.8 de train, KNN = 7 :['Pclass', 'title_cod', 'embarked_cod']\n",
      "0.89 de test <=> 0.82 de train, KNN = 7 :['Pclass', 'title_cod', 'embarked_cod', 'deck_cod']\n",
      "0.87 de test <=> 0.81 de train, KNN = 6 :['Pclass', 'title_cod', 'deck_cod']\n",
      "0.71 de test <=> 0.72 de train, KNN = 8 :['Pclass', 'Age']\n",
      "0.74 de test <=> 0.74 de train, KNN = 8 :['Pclass', 'Age', 'family_on_board']\n",
      "0.72 de test <=> 0.82 de train, KNN = 3 :['Pclass', 'Age', 'family_on_board', 'Fare']\n",
      "0.75 de test <=> 0.76 de train, KNN = 7 :['Pclass', 'Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.75 de train, KNN = 9 :['Pclass', 'Age', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.76 de test <=> 0.75 de train, KNN = 9 :['Pclass', 'Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.74 de test <=> 0.79 de train, KNN = 4 :['Pclass', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.77 de test <=> 0.79 de train, KNN = 4 :['Pclass', 'Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.79 de test <=> 0.76 de train, KNN = 6 :['Pclass', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.72 de test <=> 0.81 de train, KNN = 3 :['Pclass', 'Age', 'Fare']\n",
      "0.75 de test <=> 0.75 de train, KNN = 7 :['Pclass', 'Age', 'Fare', 'embarked_cod']\n",
      "0.74 de test <=> 0.79 de train, KNN = 5 :['Pclass', 'Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.73 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'Age', 'Fare', 'deck_cod']\n",
      "0.73 de test <=> 0.74 de train, KNN = 8 :['Pclass', 'Age', 'embarked_cod']\n",
      "0.77 de test <=> 0.76 de train, KNN = 6 :['Pclass', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.74 de test <=> 0.76 de train, KNN = 7 :['Pclass', 'Age', 'deck_cod']\n",
      "0.74 de test <=> 0.7 de train, KNN = 9 :['Pclass', 'family_on_board']\n",
      "0.72 de test <=> 0.75 de train, KNN = 9 :['Pclass', 'family_on_board', 'Fare']\n",
      "0.72 de test <=> 0.77 de train, KNN = 5 :['Pclass', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.91 de train, KNN = 1 :['Pclass', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.79 de test <=> 0.84 de train, KNN = 3 :['Pclass', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.76 de test <=> 0.7 de train, KNN = 7 :['Pclass', 'family_on_board', 'embarked_cod']\n",
      "0.79 de test <=> 0.77 de train, KNN = 9 :['Pclass', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.77 de test <=> 0.74 de train, KNN = 5 :['Pclass', 'family_on_board', 'deck_cod']\n",
      "0.7 de test <=> 0.73 de train, KNN = 9 :['Pclass', 'Fare']\n",
      "0.71 de test <=> 0.73 de train, KNN = 9 :['Pclass', 'Fare', 'embarked_cod']\n",
      "0.76 de test <=> 0.87 de train, KNN = 2 :['Pclass', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.77 de test <=> 0.87 de train, KNN = 2 :['Pclass', 'Fare', 'deck_cod']\n",
      "0.7 de test <=> 0.68 de train, KNN = 9 :['Pclass', 'embarked_cod']\n",
      "0.8 de test <=> 0.74 de train, KNN = 9 :['Pclass', 'embarked_cod', 'deck_cod']\n",
      "0.75 de test <=> 0.7 de train, KNN = 3 :['Pclass', 'deck_cod']\n",
      "0.84 de test <=> 0.77 de train, KNN = 1 :['sex_cod']\n",
      "0.84 de test <=> 0.77 de train, KNN = 4 :['sex_cod', 'title_cod']\n",
      "0.83 de test <=> 0.77 de train, KNN = 7 :['sex_cod', 'title_cod', 'Age']\n",
      "0.84 de test <=> 0.81 de train, KNN = 5 :['sex_cod', 'title_cod', 'Age', 'family_on_board']\n",
      "0.75 de test <=> 0.83 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'family_on_board', 'Fare']\n",
      "0.75 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.79 de test <=> 0.82 de train, KNN = 2 :['sex_cod', 'title_cod', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.83 de test <=> 0.95 de train, KNN = 1 :['sex_cod', 'title_cod', 'Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.84 de test <=> 0.94 de train, KNN = 1 :['sex_cod', 'title_cod', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.75 de test <=> 0.83 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'Fare']\n",
      "0.75 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'Fare', 'embarked_cod']\n",
      "0.78 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.77 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'title_cod', 'Age', 'Fare', 'deck_cod']\n",
      "0.79 de test <=> 0.83 de train, KNN = 1 :['sex_cod', 'title_cod', 'Age', 'embarked_cod']\n",
      "0.79 de test <=> 0.94 de train, KNN = 1 :['sex_cod', 'title_cod', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.8 de test <=> 0.91 de train, KNN = 1 :['sex_cod', 'title_cod', 'Age', 'deck_cod']\n",
      "0.85 de test <=> 0.8 de train, KNN = 4 :['sex_cod', 'title_cod', 'family_on_board']\n",
      "0.82 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'title_cod', 'family_on_board', 'Fare']\n",
      "0.79 de test <=> 0.79 de train, KNN = 9 :['sex_cod', 'title_cod', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.81 de test <=> 0.88 de train, KNN = 3 :['sex_cod', 'title_cod', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.81 de test <=> 0.88 de train, KNN = 3 :['sex_cod', 'title_cod', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.89 de test <=> 0.81 de train, KNN = 7 :['sex_cod', 'title_cod', 'family_on_board', 'embarked_cod']\n",
      "0.87 de test <=> 0.82 de train, KNN = 7 :['sex_cod', 'title_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.87 de test <=> 0.81 de train, KNN = 6 :['sex_cod', 'title_cod', 'family_on_board', 'deck_cod']\n",
      "0.83 de test <=> 0.78 de train, KNN = 9 :['sex_cod', 'title_cod', 'Fare']\n",
      "0.81 de test <=> 0.78 de train, KNN = 9 :['sex_cod', 'title_cod', 'Fare', 'embarked_cod']\n",
      "0.79 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'title_cod', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.8 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'title_cod', 'Fare', 'deck_cod']\n",
      "0.83 de test <=> 0.79 de train, KNN = 9 :['sex_cod', 'title_cod', 'embarked_cod']\n",
      "0.85 de test <=> 0.8 de train, KNN = 8 :['sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.78 de train, KNN = 6 :['sex_cod', 'title_cod', 'deck_cod']\n",
      "0.84 de test <=> 0.79 de train, KNN = 7 :['sex_cod', 'Age']\n",
      "0.84 de test <=> 0.82 de train, KNN = 5 :['sex_cod', 'Age', 'family_on_board']\n",
      "0.76 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'Fare']\n",
      "0.77 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.77 de test <=> 0.85 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.8 de test <=> 0.83 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.82 de test <=> 0.87 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.83 de test <=> 0.85 de train, KNN = 3 :['sex_cod', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.76 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'Age', 'Fare']\n",
      "0.76 de test <=> 0.84 de train, KNN = 3 :['sex_cod', 'Age', 'Fare', 'embarked_cod']\n",
      "0.78 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.78 de test <=> 0.86 de train, KNN = 3 :['sex_cod', 'Age', 'Fare', 'deck_cod']\n",
      "0.82 de test <=> 0.8 de train, KNN = 5 :['sex_cod', 'Age', 'embarked_cod']\n",
      "0.82 de test <=> 0.85 de train, KNN = 3 :['sex_cod', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.8 de test <=> 0.82 de train, KNN = 3 :['sex_cod', 'Age', 'deck_cod']\n",
      "0.87 de test <=> 0.79 de train, KNN = 6 :['sex_cod', 'family_on_board']\n",
      "0.82 de test <=> 0.9 de train, KNN = 1 :['sex_cod', 'family_on_board', 'Fare']\n",
      "0.8 de test <=> 0.9 de train, KNN = 1 :['sex_cod', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.79 de test <=> 0.95 de train, KNN = 1 :['sex_cod', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.81 de test <=> 0.95 de train, KNN = 1 :['sex_cod', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.87 de test <=> 0.79 de train, KNN = 6 :['sex_cod', 'family_on_board', 'embarked_cod']\n",
      "0.84 de test <=> 0.82 de train, KNN = 4 :['sex_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.8 de train, KNN = 7 :['sex_cod', 'family_on_board', 'deck_cod']\n",
      "0.81 de test <=> 0.88 de train, KNN = 1 :['sex_cod', 'Fare']\n",
      "0.79 de test <=> 0.79 de train, KNN = 7 :['sex_cod', 'Fare', 'embarked_cod']\n",
      "0.8 de test <=> 0.89 de train, KNN = 2 :['sex_cod', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.81 de test <=> 0.9 de train, KNN = 2 :['sex_cod', 'Fare', 'deck_cod']\n",
      "0.84 de test <=> 0.77 de train, KNN = 8 :['sex_cod', 'embarked_cod']\n",
      "0.83 de test <=> 0.78 de train, KNN = 7 :['sex_cod', 'embarked_cod', 'deck_cod']\n",
      "0.84 de test <=> 0.77 de train, KNN = 9 :['sex_cod', 'deck_cod']\n",
      "0.84 de test <=> 0.77 de train, KNN = 5 :['title_cod']\n",
      "0.79 de test <=> 0.78 de train, KNN = 7 :['title_cod', 'Age']\n",
      "0.8 de test <=> 0.8 de train, KNN = 5 :['title_cod', 'Age', 'family_on_board']\n",
      "0.75 de test <=> 0.75 de train, KNN = 9 :['title_cod', 'Age', 'family_on_board', 'Fare']\n",
      "0.76 de test <=> 0.76 de train, KNN = 6 :['title_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.76 de test <=> 0.81 de train, KNN = 4 :['title_cod', 'Age', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.76 de test <=> 0.8 de train, KNN = 4 :['title_cod', 'Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.76 de test <=> 0.79 de train, KNN = 5 :['title_cod', 'Age', 'family_on_board', 'embarked_cod']\n",
      "0.82 de test <=> 0.95 de train, KNN = 1 :['title_cod', 'Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.8 de test <=> 0.94 de train, KNN = 1 :['title_cod', 'Age', 'family_on_board', 'deck_cod']\n",
      "0.75 de test <=> 0.75 de train, KNN = 7 :['title_cod', 'Age', 'Fare']\n",
      "0.76 de test <=> 0.76 de train, KNN = 7 :['title_cod', 'Age', 'Fare', 'embarked_cod']\n",
      "0.76 de test <=> 0.86 de train, KNN = 3 :['title_cod', 'Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.76 de test <=> 0.86 de train, KNN = 3 :['title_cod', 'Age', 'Fare', 'deck_cod']\n",
      "0.79 de test <=> 0.83 de train, KNN = 1 :['title_cod', 'Age', 'embarked_cod']\n",
      "0.79 de test <=> 0.94 de train, KNN = 1 :['title_cod', 'Age', 'embarked_cod', 'deck_cod']\n",
      "0.79 de test <=> 0.91 de train, KNN = 1 :['title_cod', 'Age', 'deck_cod']\n",
      "0.85 de test <=> 0.8 de train, KNN = 4 :['title_cod', 'family_on_board']\n",
      "0.8 de test <=> 0.91 de train, KNN = 1 :['title_cod', 'family_on_board', 'Fare']\n",
      "0.77 de test <=> 0.91 de train, KNN = 1 :['title_cod', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.79 de test <=> 0.87 de train, KNN = 3 :['title_cod', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.82 de test <=> 0.88 de train, KNN = 3 :['title_cod', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.89 de test <=> 0.81 de train, KNN = 7 :['title_cod', 'family_on_board', 'embarked_cod']\n",
      "0.83 de test <=> 0.81 de train, KNN = 2 :['title_cod', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.81 de train, KNN = 5 :['title_cod', 'family_on_board', 'deck_cod']\n",
      "0.83 de test <=> 0.77 de train, KNN = 9 :['title_cod', 'Fare']\n",
      "0.78 de test <=> 0.82 de train, KNN = 3 :['title_cod', 'Fare', 'embarked_cod']\n",
      "0.79 de test <=> 0.85 de train, KNN = 3 :['title_cod', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.81 de test <=> 0.86 de train, KNN = 3 :['title_cod', 'Fare', 'deck_cod']\n",
      "0.83 de test <=> 0.79 de train, KNN = 9 :['title_cod', 'embarked_cod']\n",
      "0.84 de test <=> 0.8 de train, KNN = 5 :['title_cod', 'embarked_cod', 'deck_cod']\n",
      "0.85 de test <=> 0.78 de train, KNN = 6 :['title_cod', 'deck_cod']\n",
      "0.64 de test <=> 0.67 de train, KNN = 8 :['Age']\n",
      "0.7 de test <=> 0.7 de train, KNN = 6 :['Age', 'family_on_board']\n",
      "0.72 de test <=> 0.83 de train, KNN = 3 :['Age', 'family_on_board', 'Fare']\n",
      "0.75 de test <=> 0.75 de train, KNN = 7 :['Age', 'family_on_board', 'Fare', 'embarked_cod']\n",
      "0.75 de test <=> 0.75 de train, KNN = 9 :['Age', 'family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.75 de test <=> 0.75 de train, KNN = 9 :['Age', 'family_on_board', 'Fare', 'deck_cod']\n",
      "0.72 de test <=> 0.72 de train, KNN = 6 :['Age', 'family_on_board', 'embarked_cod']\n",
      "0.76 de test <=> 0.81 de train, KNN = 3 :['Age', 'family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.76 de test <=> 0.73 de train, KNN = 6 :['Age', 'family_on_board', 'deck_cod']\n",
      "0.72 de test <=> 0.82 de train, KNN = 3 :['Age', 'Fare']\n",
      "0.75 de test <=> 0.74 de train, KNN = 6 :['Age', 'Fare', 'embarked_cod']\n",
      "0.74 de test <=> 0.75 de train, KNN = 9 :['Age', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.73 de test <=> 0.84 de train, KNN = 3 :['Age', 'Fare', 'deck_cod']\n",
      "0.68 de test <=> 0.69 de train, KNN = 6 :['Age', 'embarked_cod']\n",
      "0.7 de test <=> 0.71 de train, KNN = 9 :['Age', 'embarked_cod', 'deck_cod']\n",
      "0.69 de test <=> 0.75 de train, KNN = 3 :['Age', 'deck_cod']\n",
      "0.74 de test <=> 0.65 de train, KNN = 5 :['family_on_board']\n",
      "0.73 de test <=> 0.77 de train, KNN = 5 :['family_on_board', 'Fare']\n",
      "0.7 de test <=> 0.76 de train, KNN = 5 :['family_on_board', 'Fare', 'embarked_cod']\n",
      "0.77 de test <=> 0.84 de train, KNN = 3 :['family_on_board', 'Fare', 'embarked_cod', 'deck_cod']\n",
      "0.79 de test <=> 0.85 de train, KNN = 5 :['family_on_board', 'Fare', 'deck_cod']\n",
      "0.73 de test <=> 0.66 de train, KNN = 9 :['family_on_board', 'embarked_cod']\n",
      "0.77 de test <=> 0.74 de train, KNN = 9 :['family_on_board', 'embarked_cod', 'deck_cod']\n",
      "0.72 de test <=> 0.68 de train, KNN = 9 :['family_on_board', 'deck_cod']\n",
      "0.72 de test <=> 0.73 de train, KNN = 9 :['Fare']\n",
      "0.71 de test <=> 0.75 de train, KNN = 7 :['Fare', 'embarked_cod']\n",
      "0.76 de test <=> 0.87 de train, KNN = 2 :['Fare', 'embarked_cod', 'deck_cod']\n",
      "0.77 de test <=> 0.87 de train, KNN = 2 :['Fare', 'deck_cod']\n",
      "0.69 de test <=> 0.62 de train, KNN = 1 :['embarked_cod']\n",
      "0.74 de test <=> 0.68 de train, KNN = 3 :['embarked_cod', 'deck_cod']\n",
      "0.66 de test <=> 0.62 de train, KNN = 4 :['deck_cod']\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Score 0.9 de test <=> 0.83 de train, KNN= 7 avec les colonnes : ['Pclass', 'sex_cod', 'title_cod', 'embarked_cod', 'deck_cod']\n"
     ]
    }
   ],
   "source": [
    "# Mise en commentaire pour ne traiter que lorsque le meilleur modèle n'a pas été sauvegardé.\n",
    "# better_model, better_columns, test_res = knn_found_better_config(X_train, X_test, y_train, y_test, knn_min=1, knn_max=10, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'sex_cod', 'Titre', 'title_cod', 'Age',\n",
       "       'family_on_board', 'Fare', 'embarked_cod', 'Deck', 'deck_cod',\n",
       "       'Last_name', 'First_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass   1   2    3\n",
       "Deck               \n",
       "A       19  18   25\n",
       "B       54   3   74\n",
       "C       75   5   15\n",
       "D       29  16   11\n",
       "E       27  20   33\n",
       "F        0  41   36\n",
       "G       12  81  297"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df_clean['Deck'], df_clean['Pclass'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
